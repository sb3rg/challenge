df$c,
p=68,
list=T,
times=1
)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
set.seed(12345)
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx]
test <- df[-train_idx]
train
test
df
train_idx
df[train_idx]
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx,]
test <- df[-train_idx,]
train
test
c.glm <- train %>%
glm(
formula=c ~ a+b,
data=.,
family=binomial
)
test$pred <- predict(model, test, type='response')
test$pred <- predict(c.glm, test, type='response')
test$pred
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx,]
test <- df[-train_idx,]
### STEP 2: create the glm model
c.glm <- train %>%
glm(
formula=c ~ a+b,
data=.,
family=binomial
)
# STEP 3:  predict how well the training model performs on the testing
# data.  Choosing a threshold for the decision
test$prob <- predict(c.glm, test, type='response')
test$prob
library(dplyr)
install.packages(c("caret", "dplyr"))
install.packages("ggfortify")
library(caret)
library(dplyr)
# ##################
# ### QUESTION 5 ###
# ##################
df <- data.frame(
a=c(rnorm(80), rnorm(20,1,2)),
b=c(rnorm(80,0,3), rnorm(20,2,2)),
c=c(rep(T,80), rep(F,20))
)
### BEGIN ANALYSIS AND GRAPHS
### STEP 0: assess the types of variables involved in
### the model.  Here we see that variables 'a' and 'b'
### are both continuous and variable 'c' is discrete
### boolean/dichotmous. Given these facts, We will look
### at logistic regression models for prediction of 'c'.
### we use the binomial distribution as the link function
### for the generalized linear model
### STEP 1:  partition the data into a training set and
### a testing set.
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx,]
test <- df[-train_idx,]
### STEP 2: create the glm model
c.glm <- train %>%
glm(
formula=c ~ a+b,
data=.,
family=binomial
)
# STEP 3:  predict how well the training model performs on the testing
# data.  Choose a threshold for the decision and apply boolean--here
# we chose at threshold of 51%
test$prob <- predict(c.glm, test, type='response')
test$pred <- test %>% mutate(
model
)
library(caret)
library(dplyr)
# ##################
# ### QUESTION 5 ###
# ##################
df <- data.frame(
a=c(rnorm(80), rnorm(20,1,2)),
b=c(rnorm(80,0,3), rnorm(20,2,2)),
c=c(rep(T,80), rep(F,20))
)
### BEGIN ANALYSIS AND GRAPHS
### STEP 0: assess the types of variables involved in
### the model.  Here we see that variables 'a' and 'b'
### are both continuous and variable 'c' is discrete
### boolean/dichotmous. Given these facts, We will look
### at logistic regression models for prediction of 'c'.
### we use the binomial distribution as the link function
### for the generalized linear model
### STEP 1:  partition the data into a training set and
### a testing set.
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx,]
test <- df[-train_idx,]
### STEP 2: create the glm model
c.glm <- train %>%
glm(
formula=c ~ a+b,
data=.,
family=binomial
)
# STEP 3:  predict how well the training model performs on the testing
# data.  Choose a threshold and apply boolean--here
# we choose a threshold of 51%
test$prob <- predict(c.glm, test, type='response')
teste
test %>% str()
test %>% mutate(
pred = prob > threshold
)
threshold <- 0.51
test$pred <- test %>% mutate(
pred = prob > threshold
)
str(test)
pre
pred
test$prob <- predict(c.glm, test, type='response')
threshold <- 0.51
test$pred <- test$prob > threshold
test
test$prob <- predict(c.glm, test, type='response')
threshold <- 0.55
test$pred <- test$prob > threshold
test
test$prob <- predict(c.glm, test, type='response')
threshold <- 0.60
test$pred <- test$prob > threshold
test
# STEP 4: test the accuracy of the model
test$accuracy <- ifelse( test$pred == test$prob, 1, 0 )
test
# STEP 4: test the accuracy of the model
test$accuracy <- ifelse( test$pred == c, 1, 0 )
# STEP 4: test the accuracy of the model
test$accuracy <- ifelse( test$pred == test$c, 1, 0 )
test
library(caret)
library(dplyr)
# ##################
# ### QUESTION 5 ###
# ##################
df <- data.frame(
a=c(rnorm(80), rnorm(20,1,2)),
b=c(rnorm(80,0,3), rnorm(20,2,2)),
c=c(rep(T,80), rep(F,20))
)
### BEGIN ANALYSIS AND GRAPHS
### STEP 0: assess the types of variables involved in
### the model.  Here we see that variables 'a' and 'b'
### are both continuous and variable 'c' is discrete
### boolean/dichotmous.
### STEP 1:  partition the data into a training set and
### a testing set.
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx,]
test <- df[-train_idx,]
### STEP 2: Given the types of variables for predicted and
### predictors, We will look to the logistic regression model
### for predicting 'c'. We use the binomial distribution
### as the link function for the generalized linear model
c.glm <- train %>%
glm(
formula=c ~ a+b,
data=.,
family=binomial
)
### STEP 3: determine if there are any significant relationships
### between predicted variable 'c' and predictor variables
### 'a' and 'b'. (aside: we know there shouldn't be as these values
### were generated psuedo-randomly from independent 'experiments',
### but we will pretend we don't know this)
summary(c.glm)
### seeing that the p-values are both greater than 0.05, so neither
### 'a' or 'b' shares a significant relationship to 'c' in the
### logistic regression model.  With this in mind, we press forward
### to attempt prediction knowing its accuracy will not be significant.
# STEP 4:  predict how well the training model performs on the testing
# data.  Choose a threshold and apply boolean--here we choose a threshold of 60%
test$prob <- predict(c.glm, test, type='response')
threshold <- 0.60
test$pred <- test$prob > threshold
# STEP 4: test the accuracy of the model
test$accuracy <- ifelse( test$pred == test$c, 1, 0 )
sum(accuracy)/nrow(test)
sum(test$accuracy)/nrow(test)
# in addition, we can use the confusion matrix to assess possible combinations
confusionMatrix(test$pred, test$c)
?confusionMatrix
factor(test$pred)
# in addition, we can use the confusion matrix to assess possible combinations
confusionMatrix(test$pred %>% factor(), test$c %>% factor())
library(caret)
library(dplyr)
install.packages("e1071")
# in addition, we can use the confusion matrix to assess possible combinations
confusionMatrix(test$pred %>% factor(), test$c %>% factor())
### STEP 5: evaluate the significance of the relationships
### between predicted variable 'c' and predictor variables
### 'a' and 'b'. (aside: we know there shouldn't be as these values
### were generated psuedo-randomly from independent 'experiments',
### but we will pretend we don't know this)
summary(c.glm)
library(caret)
# install.packages("e1071")
library(dplyr)
# ##################
# ### QUESTION 5 ###
# ##################
df <- data.frame(
a=c(rnorm(80), rnorm(20,1,2)),
b=c(rnorm(80,0,3), rnorm(20,2,2)),
c=c(rep(T,80), rep(F,20))
)
### BEGIN ANALYSIS AND GRAPHS ###############
### STEP 0: assess the types of variables involved in
### the model.  Here we see that variables 'a' and 'b'
### are both continuous and variable 'c' is discrete
### boolean/dichotmous.
### STEP 1:  partition the data into a training set and
### a testing set.
set.seed(12345)
train_idx <- createDataPartition(
df$c,
p=0.68,
list=F,
times=1
)
train <- df[train_idx,]
test <- df[-train_idx,]
### STEP 2: Given the types of variables for predicted and
### predictors, We will look to the logistic regression model
### for predicting 'c'. We use the binomial distribution
### as the link function for the generalized linear model
c.glm <- train %>%
glm(
formula=c ~ a+b,
data=.,
family=binomial
)
### STEP 3:  predict how well the training model performs on the testing
### data.  Choose a threshold and apply boolean--here we choose a threshold of 60%
test$prob <- predict(c.glm, test, type='response')
threshold <- 0.60
test$pred <- test$prob > threshold
### STEP 4: test the accuracy of the model
test$accuracy <- ifelse( test$pred == test$c, 1, 0 )
sum(test$accuracy)/nrow(test)
# output:> 0.8709677
# we can also use the confusion matrix to assess possible combinations
confusionMatrix(test$pred %>% factor(), test$c %>% factor())
### <OUTPUT FROM CONFUSION MATRIX>
# Reference
# Prediction FALSE TRUE
# FALSE     2    0
# TRUE      4   25
#
# Accuracy : 0.871
# 95% CI : (0.7017, 0.9637)
# No Information Rate : 0.8065
# P-Value [Acc > NIR] : 0.2563
#
# Kappa : 0.4464
#
# Mcnemar's Test P-Value : 0.1336
#
#             Sensitivity : 0.33333
#             Specificity : 1.00000
#          Pos Pred Value : 1.00000
#          Neg Pred Value : 0.86207
#              Prevalence : 0.19355
#          Detection Rate : 0.06452
#    Detection Prevalence : 0.06452
#       Balanced Accuracy : 0.66667
###
### here we confirm 87% accuracy as well as other evaluations of
### STEP 5: evaluate the significance of the relationships
### between predicted variable 'c' and predictor variables
### 'a' and 'b'. (aside: we know there shouldn't be as these values
### were generated psuedo-randomly from independent 'experiments',
### but we will pretend we don't know this)
summary(c.glm)
### <OUTPUT OF SUMMARY>
# Call:
#   glm(formula = c ~ a + b, family = binomial, data = .)
#
# Deviance Residuals:
#   Min       1Q   Median       3Q      Max
# -2.1121   0.2501   0.4991   0.6151   1.4755
#
# Coefficients:
#   Estimate Std. Error z value Pr(>|z|)
# (Intercept)   1.8751     0.4224   4.439 9.03e-06 ***
#   a            -0.1634     0.2532  -0.646   0.5186
# b            -0.3245     0.1248  -2.601   0.0093 **
#   ---
#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#
# (Dispersion parameter for binomial family taken to be 1)
#
# Null deviance: 69.606  on 68  degrees of freedom
# Residual deviance: 61.033  on 66  degrees of freedom
# AIC: 67.033
#
# Number of Fisher Scoring iterations: 5
###
### seeing that the p-values are both greater than 0.05, so neither
### 'a' or 'b' shares a significant relationship to 'c' in the
### logistic regression model.
# STEP 6:  CONCLUSION
# While the model did produce an accuracy of 87%, the relationship
# between predictors on predicted are insignificant given both
# knowledge of the data produced and the results of significance
# testing.  The model is not a strong candidate for predicting
# values of 'c' based on 'a' and 'b'
### END ANALYSIS AND GRAPHS
rm(list=ls())
library(ggfortify)
# ##################
# ### QUESTION 4 ###
# ##################
# set size of samples
N <- 512
# create two indices 8 and 16
inds <- c(8, 16)
# scaling factor for signal amplitude in frequency domain
b <- 30
# set the number of samples per unit time--sampling frequency
a <- 128
# sample 512 values from the normal distribution
s <- rnorm(N)
# perform the fast discrete fourier transform of the sample data
# return a vector of complex numbers representing Real and
# Imaginary parts.  This converts these values into the frequency
# domain representation of a theoretical sampling interval
x <- fft(s)
# repeat false (N/2-1) times.
logind <- rep(F, N/2-1)
# replace two falses at index 8 and 16 in the vector
logind[inds] <- T
# concatenate logind vector with leading and trailing FALSe values with
# the added concatenation of the reverse of the original vector
logind <- c(F, logind, F, rev(logind))
# replace four complex numbers after scaling by 'b'
# the indices are now c(9,17,497, 505)
x[logind] <- b*x[logind]
# take the inverse discrete fourier transform of the scaled response
# divide the values by half and return only the real component of
# complex number.
y <- Re(fft(x, inverse=T)/length(x))
# generate a time series object scaled to a range that's in the
# standard normal distribution
result <- ts(y/sd(y), frequency=a)
## BEGIN ANALYSIS AND GRAPHS
result %>% autoplot()+
## TITLES & AXES
labs( # draw labels
y = "Result",
x = "Time"
)+
theme_classic()
ggsave(path="./", filename="q4_result_ts.png", height = 4.78, width = 8.75, units = "in", device = "png" )
## END ANALYSIS AND GRAPHS
### RESPONSE NOTES ############################
### This is a digital signal processing method.
###
### The high-level overview of what's happening with the code chunk is
### that we're simulating time series data by amplifying certain frequencies
### in the frequency domain so that when we transform the signal back to the
### time domain (inverse DFT), the signal has the desired periodicities.
### The code does this while preserving the original statistical parameters
### of the sampling distribution.
###
### The reason why we have to mirror the signal is to account for aliasing about the
### nyquist frequency and preserving information about the original signal when
### performing the inverse transform.
###############################################
rm(list=ls())
library(ggplot2)
library(data.table)
library(magrittr)
# ##################
# ### QUESTION 3 ###
# ##################
### RESPONSE NOTES ############################
### The data being generated by 'rnorm(100)' first follows the behavior of a hundred values sampled from a standard normal distribution,
### where by default rnorm sets parameters mean to zero and the standard deviation to 1.  These hundred samples are returned in a numeric
### vector in R.  After, the cumulative sum indicated by the 'cumsum()' function creates a running total of
### the hundred samples.  Graphically the function generates the following:
###############################################
## BEGIN ANALYSIS AND GRAPHS
x <- rnorm(100)
y <- x %>% cumsum()
DT <- data.table(x=x, y=y)
DT %>%
ggplot(aes(x=x, y=y))+
geom_line()+
theme_classic()
ggsave(path="./", filename="q3_cumsum_random_walk.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_random_walk1.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_random_walk2.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_random_walk3.png", height = 4.78, width = 8.75, units = "in", device = "png" )
## END ANALYSIS AND GRAPHS
### RESPONSE NOTES (continued) ################
### upon investigating a line graph chart (one example being 'q3_cumsum_random_walk') of the cumulative distribution, the generated data
### seems to follow a random walk or brownian motion.  Running multiple iterations of 100 samples reveals that the random walk is sensistive
### to initial conditions. Because the distribution looks at first blush multi-modal, we should investigate the long-run statistics of the
### generated data at higher values of N.  This effort reveals graphs 'q3_cumsum_dist_100' to 'q3_cumsum_dist_100000'.
###############################################
## BEGIN ANALYSIS AND GRAPHS
DT %>%
ggplot(aes(x=y, y=..count../sum(..count..)))+
geom_histogram(binwidth=1)+
theme_classic()
ggsave(path="./", filename="q3_cumsum_dist.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_dist_100.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_dist_1000.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_dist_10000.png", height = 4.78, width = 8.75, units = "in", device = "png" )
# ggsave(path="./", filename="q3_cumsum_dist_100000.png", height = 4.78, width = 8.75, units = "in", device = "png" )
## END ANALYSIS AND GRAPHS
### RESPONSE NOTES (continued) ################
### More generally, we develop a general sense of statistical parameters for the long-run behavior of the generated data as shown in the
### following graphs.
###############################################
## BEGIN ANALYSIS AND GRAPHS
# look at stat params for increasing values of N
N <- 2:1000
list_of_cumsums <- N %>% lapply(rnorm) %>% lapply(cumsum)
mean <- list_of_cumsums %>% lapply(mean) %>% unlist()
std_dev <- list_of_cumsums %>% lapply(sd) %>% unlist()
DT2 <- data.table(N=N, mean=mean, std_dev=std_dev)
DT2 %>%
ggplot(aes(x=N, y=std_dev))+
geom_point()+
geom_smooth()+
theme_classic()
ggsave(path="./", filename="q3_cumsum_std_dev.png", height = 4.78, width = 8.75, units = "in", device = "png" )
DT2 %>%
ggplot(aes(x=N, y=mean))+
geom_point()+
geom_smooth()+
theme_classic()
ggsave(path="./", filename="q3_cumsum_mean.png", height = 4.78, width = 8.75, units = "in", device = "png" )
## END ANALYSIS AND GRAPHS
### RESPONSE NOTES (continued) ################
### In viewing the means and standard deviations with respect to increasing N according to graphs 'q3_cumsum_mean' and 'q3_cumsum_std_dev',
### respectively, it looks like the long run statistics of the generated data yields a mean that stabilizes around zero, but has INCREASING
### variance.
###############################################
DT2 %>%
ggplot(aes(x=N, y=std_dev))+
geom_point()+
geom_smooth()+
theme_classic()
DT2 %>%
ggplot(aes(x=N, y=mean))+
geom_point()+
geom_smooth()+
theme_classic()
